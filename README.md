# PowerBI Ontology Extractor

<div align="center">

![PowerBI Ontology Extractor](https://img.shields.io/badge/PowerBI-Ontology%20Extractor-blue?style=for-the-badge)

**Transform 20 million Power BI dashboards into AI-ready ontologies**

[![Tests](https://img.shields.io/badge/tests-370%20passed-brightgreen)](https://github.com/vpakspace/powerbi-ontology-extractor)
[![Coverage](https://img.shields.io/badge/coverage-81%25-green)](https://github.com/vpakspace/powerbi-ontology-extractor)
[![Security](https://img.shields.io/badge/security-hardened-blue)](https://github.com/vpakspace/powerbi-ontology-extractor)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyPI version](https://img.shields.io/pypi/v/powerbi-ontology-extractor.svg)](https://pypi.org/project/powerbi-ontology-extractor/)

[Installation](#installation) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Features](#-key-features) ‚Ä¢ [Documentation](#-documentation) ‚Ä¢ [Contributing](#-contributing)

</div>

---

## üéØ The Problem

Enterprises have **20+ million Power BI semantic models** that are actually **informal ontologies** trapped in proprietary .pbix files.

- **The Challenge**: Each Power BI model contains entities, relationships, and business logic‚Äîbut AI agents can't access this semantic intelligence
- **The Cost**: Enterprises spend $50K-$200K per semantic definition to reconcile conflicts across dashboards
- **The $4.6M Mistake**: A logistics company lost $4.6M when an AI agent used a renamed column (`Warehouse_Location` ‚Üí `FacilityID`) because there was no semantic binding validation

## üí° The Solution

PowerBI Ontology Extractor **unlocks the hidden ontologies** in your Power BI dashboards and transforms them into formal, AI-ready ontologies.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Power BI .pbix    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Ontology Extractor  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ       OntoGuard             ‚îÇ
‚îÇ  (20M+ dashboards)  ‚îÇ     ‚îÇ  (this project)      ‚îÇ     ‚îÇ  Semantic Firewall          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ                              ‚îÇ
                                     ‚îÇ OWL/Fabric IQ                ‚îÇ Semantic Validation
                                     ‚ñº                              ‚ñº
                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                            ‚îÇ   Semantic Contract  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Universal Agent Connector  ‚îÇ
                            ‚îÇ   (permissions)      ‚îÇ     ‚îÇ  AI Agent Infrastructure    ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                    ‚îÇ
                                                                    ‚ñº
                                                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                         ‚îÇ       AI Agents             ‚îÇ
                                                         ‚îÇ  (Claude, GPT, etc.)        ‚îÇ
                                                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**30-minute workflow**:
```
Power BI (.pbix) ‚Üí Ontology Extractor ‚Üí OntoGuard ‚Üí Universal Agent Connector ‚Üí AI Agent
     10 min           10 min            5 min            3 min               2 min
```

---

## üöÄ Quick Start

### Installation

```bash
# Install from PyPI (recommended)
pip install powerbi-ontology-extractor
```

**Or install from source:**

```bash
git clone https://github.com/vpakspace/powerbi-ontology-extractor.git
cd powerbi-ontology-extractor
pip install -e .
```

### Basic Usage

```python
from powerbi_ontology import PowerBIExtractor, OntologyGenerator

# Step 1: Extract semantic model from Power BI
extractor = PowerBIExtractor("path/to/dashboard.pbix")
semantic_model = extractor.extract()

# Step 2: Generate formal ontology
generator = OntologyGenerator(semantic_model)
ontology = generator.generate()

print(f"‚úÖ Extracted {len(ontology.entities)} entities")
print(f"‚úÖ Found {len(ontology.relationships)} relationships")
print(f"‚úÖ Generated {len(ontology.business_rules)} business rules")

# Step 3: Export to OWL for OntoGuard
from powerbi_ontology.export import OWLExporter

exporter = OWLExporter(ontology)
exporter.save("ontology.owl")
```

### Visual Ontology Editor (No-Code UI)

```bash
# Start Streamlit UI
streamlit run ontology_editor.py --server.port 8503
```

**Features**:
- üìÇ Load from .pbix files or JSON
- üì¶ Edit entities with properties and constraints
- üîó Manage relationships between entities
- üîê Configure permission matrix (RBAC)
- üìú Add business rules with classification
- ü¶â Preview and export OWL
- üîÄ Diff & Merge ontology versions
- üí¨ **AI Chat** - Ask questions about your ontology!

---

## üî• Key Features

### 1. Automatic Extraction (PBIXRay)
- ‚úÖ Reads Power BI .pbix files (binary DataModel via PBIXRay)
- ‚úÖ Extracts tables, columns, relationships, hierarchies
- ‚úÖ Parses DAX measures and calculated columns
- ‚úÖ Captures Row-Level Security (RLS) rules
- ‚úÖ Fallback to JSON model.bim for legacy files

### 2. DAX to Business Rules
- ‚úÖ Parses DAX formulas automatically
- ‚úÖ Extracts conditional logic (IF, SWITCH, CALCULATE)
- ‚úÖ Converts filters to business rules
- ‚úÖ Classifies measure types (aggregation, conditional, time intelligence)

### 3. Ontology Generation (70% Automated)
- ‚úÖ Entities from tables
- ‚úÖ Properties from columns (with data types)
- ‚úÖ Relationships from foreign keys (with cardinality)
- ‚úÖ Business rules from DAX measures
- ‚úÖ Constraints (required, unique, range, regex, enum)
- ‚úÖ Pattern detection (date tables, dimensions, facts)

### 4. Multi-Format Export
| Format | Use Case |
|--------|----------|
| **OWL/RDF** | OntoGuard semantic validation |
| **Fabric IQ** | Microsoft Fabric deployment |
| **JSON** | Universal agent connector |
| **Semantic Contract** | Role-based AI agent permissions |

### 5. Schema Drift Detection (Prevents $4.6M Mistakes!)
- ‚úÖ Validates schema bindings
- ‚úÖ Detects column renames/deletions
- ‚úÖ Type normalization (varchar‚Üítext, int‚Üíinteger)
- ‚úÖ Severity levels: CRITICAL, WARNING, INFO
- ‚úÖ Auto-fix suggestions

### 6. Multi-Dashboard Semantic Debt Analysis
- ‚úÖ Analyzes multiple Power BI dashboards
- ‚úÖ Detects conflicting definitions ("Revenue" defined differently)
- ‚úÖ 5 conflict types: MEASURE, TYPE, ENTITY, RELATIONSHIP, RULE
- ‚úÖ Generates consolidation reports

### 7. Ontology Diff & Merge
- ‚úÖ Git-like diff between ontology versions
- ‚úÖ Detect added/removed/modified elements
- ‚úÖ Three-way merge (base, ours, theirs)
- ‚úÖ Conflict detection and resolution strategies

### 8. Collaborative Review Workflow
- ‚úÖ Comments on entities/properties/rules
- ‚úÖ Reply and resolve threads
- ‚úÖ Approval workflow: draft ‚Üí review ‚Üí approved ‚Üí published
- ‚úÖ Audit trail of all actions

### 9. CLI Tool for Automation
```bash
# Extract single .pbix file
pbix2owl extract -i dashboard.pbix -o ontology.owl

# Batch process directory (8 parallel workers)
pbix2owl batch -i ./dashboards/ -o ./ontologies/ -w 8 --recursive

# Analyze semantic debt
pbix2owl analyze -i ./ontologies/ -o report.md

# Compare versions (diff)
pbix2owl diff -s v1.json -t v2.json -o changelog.md
```

### 10. AI-Powered Ontology Chat
- ‚úÖ Ask questions about loaded ontology in natural language
- ‚úÖ OpenAI API integration (gpt-4o-mini)
- ‚úÖ Role-based context (Admin/Analyst/Viewer)
- ‚úÖ Bilingual support (Russian/English)
- ‚úÖ Suggested questions based on ontology content
- ‚úÖ Rate limiting (1 req/sec) to prevent API abuse

**Example questions**:
- "What entities exist in the ontology?"
- "How are Customer and Sales related?"
- "Show all DAX measures"
- "What permissions does Analyst role have?"

### 11. Security Hardened (v0.1.1)

14 security issues identified and fixed via comprehensive code review:

| Severity | Count | Examples |
|----------|-------|---------|
| **CRITICAL** | 3 | Path traversal in file operations, XSS in chat rendering, unsafe YAML loading |
| **HIGH** | 2 | API key validation, file upload size limits (50 MB) |
| **MEDIUM** | 4 | Audit logging, DAX regex hardening, error info leakage prevention |
| **LOW** | 5 | Type hints, deterministic hashing, rate limiting, unused code cleanup |

**Security features**:
- Path traversal protection on all file write operations
- HTML escaping for chat messages (XSS prevention)
- PBIX upload validation (size + extension + ZIP structure)
- Audit trail logging for all mutating operations (`data/audit.log`)
- OpenAI API key validation before external calls
- Rate limiting on AI chat requests

---

## üìä Real-World Example

**Tested with Microsoft official samples**:

| File | Size | Entities | Relationships | DAX Measures | OWL Triples |
|------|------|----------|---------------|--------------|-------------|
| Sales_Returns_Sample.pbix | 6.3 MB | 15 | 9 | 58 | 1,734 |
| Adventure_Works_DW_2020.pbix | 7.8 MB | 11 | 13 | 0 | 1,083 |

```python
from powerbi_ontology import PowerBIExtractor, OntologyGenerator
from powerbi_ontology.export import OWLExporter

# Extract from Power BI
extractor = PowerBIExtractor("Sales_Returns_Sample.pbix")
model = extractor.extract()

# Generate ontology
ontology = OntologyGenerator(model).generate()

# Export to OWL (for OntoGuard)
exporter = OWLExporter(ontology, default_roles=["Admin", "Analyst", "Viewer"])
exporter.save("sales_ontology.owl")

# Summary
summary = exporter.get_export_summary()
print(f"Classes: {summary['classes']}")
print(f"Properties: {summary['datatype_properties']}")
print(f"Action Rules: {summary['action_rules']}")  # CRUD per entity √ó role
```

---

## üîó Integration Ecosystem

### OntoGuard (Semantic Firewall)

```python
from powerbi_ontology.export import OWLExporter

exporter = OWLExporter(ontology)
exporter.save("ontology.owl")

# Use with OntoGuard for AI agent validation
# github.com/vpakspace/ontoguard-ai
```

### Universal Agent Connector (MCP)

```python
from powerbi_ontology import ContractBuilder
from powerbi_ontology.export import ContractToOWLConverter

# Create semantic contract for AI agent
builder = ContractBuilder(ontology)
contract = builder.build_contract(
    agent_name="SalesAnalyst",
    permissions={
        "read": ["Customer", "Sales", "Product"],
        "write": {"Sales": ["Status"]},
        "execute": ["GenerateReport"]
    }
)

# Export for MCP
converter = ContractToOWLConverter(contract)
converter.save("sales_agent_contract.owl")

# Use with Universal Agent Connector
# github.com/vpakspace/universal-agent-connector
```

### Microsoft Fabric IQ

```python
from powerbi_ontology.export import FabricIQExporter

exporter = FabricIQExporter(ontology)
fabric_json = exporter.export()

# Deploy as Ontology Item to OneLake
```

---

## üß™ Testing

```bash
# Run all tests (370 tests, 81% coverage)
pytest

# Run with coverage report
pytest --cov=powerbi_ontology --cov-report=html

# Run specific test module
pytest tests/test_owl_exporter.py -v
```

**Test Statistics**:
- 370 tests passing
- 81% code coverage
- E2E tests with real .pbix files
- OntoGuard integration tests
- MCP Server tests (30 tests)

---

## üìä Evaluation

We evaluate extraction accuracy on **real Microsoft .pbix samples** (Sales_Returns_Sample, Adventure_Works_DW_2020), comparing extracted data against manually verified ground truth.

Run the evaluation:

```bash
python evaluation/run_evaluation.py
```

### Entity Extraction Accuracy

| Dataset | Precision | Recall | F1 | Entities |
|---------|-----------|--------|----|----------|
| Sales_Returns_Sample | 87% | 87% | 87% | 15 |
| Adventure_Works_DW_2020 | 100% | 100% | 100% | 11 |

### Relationship Extraction

| Dataset | Precision | Recall | F1 | Relationships |
|---------|-----------|--------|----|---------------|
| Sales_Returns_Sample | 100% | 100% | 100% | 9 |
| Adventure_Works_DW_2020 | 100% | 100% | 100% | 13 |

### DAX Subset Parser ‚Äî Pattern Coverage

**8/8** patterns handled correctly (100%):

| Pattern | Status | Notes |
|---------|--------|-------|
| `CALCULATE(expr, filter)` | PASS | Single-level only |
| `IF(condition, true, false)` | PASS | |
| `SWITCH(TRUE(), ...)` | PASS | |
| Simple thresholds (`field > value`) | PASS | |
| Nested CALCULATE | PASS | Outer level captured |
| VAR/RETURN with IF | PASS | IF inside captured |
| SUMX (iterator) | PASS | Correctly ignored (no condition) |
| Plain SUM | PASS | Correctly ignored (aggregation only) |

### OWL Export

| Dataset | OWL Triples | Business Rules | Extraction Time |
|---------|-------------|----------------|-----------------|
| Sales_Returns_Sample | 1,656 | 32 | 117 ms |
| Adventure_Works_DW_2020 | 1,083 | 0 | 73 ms |

### DAX Subset Parser ‚Äî Limitations

The regex-based DAX **subset** parser handles 4 core patterns. **Not supported**: nested CALCULATE (inner level), row context (SUMX/FILTER iterators), table constructors, SELECTEDVALUE, HASONEVALUE, and other advanced DAX patterns. See `evaluation/run_evaluation.py` for details.

---

## üìÅ Project Structure

```
powerbi-ontology-extractor/
‚îú‚îÄ‚îÄ powerbi_ontology/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ extractor.py           # PowerBIExtractor
‚îÇ   ‚îú‚îÄ‚îÄ ontology_generator.py  # OntologyGenerator
‚îÇ   ‚îú‚îÄ‚îÄ dax_parser.py          # DAX formula parsing
‚îÇ   ‚îú‚îÄ‚îÄ semantic_debt.py       # Multi-dashboard analysis
‚îÇ   ‚îú‚îÄ‚îÄ ontology_diff.py       # Diff & Merge
‚îÇ   ‚îú‚îÄ‚îÄ review.py              # Collaborative review
‚îÇ   ‚îú‚îÄ‚îÄ chat.py                # AI Chat (OpenAI, rate-limited)
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                 # CLI commands
‚îÇ   ‚îú‚îÄ‚îÄ mcp_server.py          # MCP Server for Claude Code
‚îÇ   ‚îú‚îÄ‚îÄ mcp_config.py          # MCP configuration loader
‚îÇ   ‚îú‚îÄ‚îÄ mcp_models.py          # MCP data models
‚îÇ   ‚îú‚îÄ‚îÄ export/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ owl.py             # OWL/RDF export (path-validated)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fabric_iq.py       # Fabric IQ export
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fabric_iq_to_owl.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ contract_to_owl.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ pbix_reader.py     # PBIXRay integration
‚îÇ       ‚îú‚îÄ‚îÄ visualizer.py
‚îÇ       ‚îî‚îÄ‚îÄ validators.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ mcp_config.yaml        # MCP server configuration
‚îú‚îÄ‚îÄ ontology_editor.py         # Streamlit UI (1300+ lines)
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ sample_pbix/           # Microsoft official samples
‚îÇ   ‚îî‚îÄ‚îÄ sample_ontology.json
‚îú‚îÄ‚îÄ tests/                     # 370 tests, 81% coverage
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üìä Project Status

| Feature | Status | Coverage |
|---------|--------|----------|
| PBIX Extraction (PBIXRay) | ‚úÖ Complete | 51% |
| DAX Parser | ‚úÖ Complete | 73% |
| Ontology Generator | ‚úÖ Complete | 83% |
| OWL Exporter | ‚úÖ Complete | 95% |
| Fabric IQ Exporter | ‚úÖ Complete | 97% |
| Contract Builder | ‚úÖ Complete | 98% |
| Schema Drift Detection | ‚úÖ Complete | 84% |
| Semantic Debt Analysis | ‚úÖ Complete | 84% |
| Ontology Diff & Merge | ‚úÖ Complete | 84% |
| Review Workflow | ‚úÖ Complete | 93% |
| CLI Tool | ‚úÖ Complete | 60% |
| MCP Server (Claude Code) | ‚úÖ Complete | 85% |
| Visual Editor (Streamlit) | ‚úÖ Complete | - |
| AI Chat (OpenAI) | ‚úÖ Complete | - |

**Overall**: 370 tests, 81% coverage

**Current version**: [0.1.1](https://pypi.org/project/powerbi-ontology-extractor/0.1.1/) (security patch)

**PyPI**: https://pypi.org/project/powerbi-ontology-extractor/

---

## ü§ñ MCP Server (Claude Code Integration)

Use PowerBI Ontology Extractor directly in Claude Code via MCP protocol.

### Setup

1. **Install the package**:
```bash
pip install powerbi-ontology-extractor
```

2. **Add to `~/.claude.json`**:
```json
{
  "mcpServers": {
    "powerbi-ontology": {
      "command": "python",
      "args": ["-m", "powerbi_ontology.mcp_server"]
    }
  }
}
```

> **Optional**: Add `"env": {"OPENAI_API_KEY": "..."}` for AI chat feature.

3. **Restart Claude Code**

### Available MCP Tools

| Tool | Description |
|------|-------------|
| `pbix_extract` | Extract semantic model from .pbix file |
| `ontology_generate` | Generate ontology from model data |
| `export_owl` | Export to OWL format (xml/turtle) |
| `export_json` | Export to JSON format |
| `analyze_debt` | Analyze semantic debt across ontologies |
| `ontology_diff` | Compare two ontology versions |
| `ontology_merge` | Merge ontologies (three-way) |
| `ontology_chat_ask` | AI Q&A about ontology |

### Usage Examples in Claude Code

```
# Extract and generate ontology
"Extract ontology from sales.pbix and export to OWL"

# Ask questions about ontology
"What entities are in the Sales_Returns ontology?"

# Compare versions
"Compare v1 and v2 ontologies and show differences"
```

---

## üõ†Ô∏è Development Setup

```bash
# Clone repository
git clone https://github.com/vpakspace/powerbi-ontology-extractor.git
cd powerbi-ontology-extractor

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -e .

# Run tests
pytest

# Start Streamlit UI
streamlit run ontology_editor.py --server.port 8503
```

### Environment Variables

Create `.env` file for AI Chat:
```bash
# Required for Ontology Chat
OPENAI_API_KEY=your-openai-api-key

# Optional: Model selection (default: gpt-4o-mini)
# OPENAI_MODEL=gpt-4o-mini

# Optional: Local models via Ollama
# OLLAMA_BASE_URL=http://localhost:11434/v1
```

---

## ü§ù Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Ways to contribute**:
- üêõ Report bugs via [GitHub Issues](https://github.com/vpakspace/powerbi-ontology-extractor/issues)
- üí° Suggest features
- üìù Improve documentation
- üîß Submit pull requests
- ‚≠ê Star the repository

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üîó Related Projects

| Project | Description |
|---------|-------------|
| [OntoGuard AI](https://github.com/vpakspace/ontoguard-ai) | Semantic Firewall for AI Agents |
| [Universal Agent Connector](https://github.com/vpakspace/universal-agent-connector) | MCP Infrastructure + Streamlit UI |

---

## üìû Contact

- üêõ **Issues**: [GitHub Issues](https://github.com/vpakspace/powerbi-ontology-extractor/issues)
- üí¨ **Discussions**: [GitHub Discussions](https://github.com/vpakspace/powerbi-ontology-extractor/discussions)

---

<div align="center">

**Ready to unlock the semantic intelligence in your Power BI dashboards?**

```bash
pip install powerbi-ontology-extractor
```

**Star this repo if you find it useful!**

</div>
